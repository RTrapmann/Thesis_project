{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets \n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "from art import attacks \n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, CarliniL0Method, BasicIterativeMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.defences.trainer import AdversarialTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'today' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hallo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = \"hallo\" \n",
    "%store today \n",
    "\n",
    "\n",
    "# other notebook \n",
    "%store -r today \n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters  \n",
    "epochs = 30  #the nn will train 29 times \n",
    "learning_rate = 0.0001 #how much the weight will be updated each time \n",
    "batch_size = 64 \n",
    "classes = 43 \n",
    "img_size = 32\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3403, 0.3121, 0.3214),\n",
    "                        (0.2724, 0.2608, 0.2669))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.GTSRB(\n",
    "    root='./data', split = 'test', transform=transforms, download=True)\n",
    "\n",
    "# train loader \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size\n",
    ", shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<torch.utils.data.dataloader.DataLoader object at 0x7f34bbe0fa30>, <torch.utils.data.dataloader.DataLoader object at 0x7f34a97e1a60>)\n"
     ]
    }
   ],
   "source": [
    "def get_train_valid_loader(\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           num_workers=2):\n",
    "\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "\n",
    "    # load the dataset\n",
    "    global base_dataset\n",
    "    base_dataset = torchvision.datasets.GTSRB(\n",
    "    root='./data', split = 'train', transform=transforms, download=True)\n",
    "\n",
    "    # TODO\n",
    "    split_datasets = torch.utils.data.random_split(base_dataset, [0.20,0.8])\n",
    "    global val_dataset, train_dataset\n",
    "    val_dataset = split_datasets[0]\n",
    "    train_dataset = split_datasets[1]\n",
    "    \n",
    "\n",
    "    global num_train \n",
    "    num_train= len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    global split \n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "    #train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    #train_sampler = SubsetRandomSampler(train_idx)\n",
    "    #valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "    global train_loader \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = train_sampler\n",
    "    )\n",
    "    global valid_loader \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = valid_sampler\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "print(get_train_valid_loader(batch_size = 64, augment = True, random_seed = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    Function for plotting training and validation losses\n",
    "    '''\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        y_hat= model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function, without a learning step (backward pass)\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # Forward pass and record loss\n",
    "        y_hat= model(X)    # predicted\n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    \n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(2048,43)\n",
    "model.conv1 = torch.nn.Conv2d(3,64,kernel_size=5,stride=1)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(random_seed)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:04:17 --- Epoch: 0\tTrain loss: 2.5749\tValid loss: 1.5447\tTrain accuracy: 58.67\tValid accuracy: 53.96\n",
      "23:04:33 --- Epoch: 1\tTrain loss: 0.9801\tValid loss: 0.6248\tTrain accuracy: 87.52\tValid accuracy: 80.87\n",
      "23:04:49 --- Epoch: 2\tTrain loss: 0.3197\tValid loss: 0.3487\tTrain accuracy: 95.96\tValid accuracy: 89.34\n",
      "23:05:05 --- Epoch: 3\tTrain loss: 0.0930\tValid loss: 0.2538\tTrain accuracy: 97.96\tValid accuracy: 92.38\n",
      "23:05:21 --- Epoch: 4\tTrain loss: 0.0484\tValid loss: 0.2794\tTrain accuracy: 97.43\tValid accuracy: 91.39\n",
      "23:05:37 --- Epoch: 5\tTrain loss: 0.0779\tValid loss: 0.3201\tTrain accuracy: 96.40\tValid accuracy: 90.50\n",
      "23:05:53 --- Epoch: 6\tTrain loss: 0.0780\tValid loss: 0.2331\tTrain accuracy: 97.68\tValid accuracy: 93.49\n",
      "23:06:09 --- Epoch: 7\tTrain loss: 0.0647\tValid loss: 0.2742\tTrain accuracy: 96.74\tValid accuracy: 92.72\n",
      "23:06:25 --- Epoch: 8\tTrain loss: 0.0545\tValid loss: 0.1918\tTrain accuracy: 98.35\tValid accuracy: 94.54\n",
      "23:06:42 --- Epoch: 9\tTrain loss: 0.0583\tValid loss: 0.2024\tTrain accuracy: 98.20\tValid accuracy: 94.95\n",
      "23:06:58 --- Epoch: 10\tTrain loss: 0.0432\tValid loss: 0.1513\tTrain accuracy: 99.00\tValid accuracy: 95.91\n",
      "23:07:14 --- Epoch: 11\tTrain loss: 0.0328\tValid loss: 0.1408\tTrain accuracy: 99.31\tValid accuracy: 96.27\n",
      "23:07:30 --- Epoch: 12\tTrain loss: 0.0462\tValid loss: 0.2077\tTrain accuracy: 97.34\tValid accuracy: 94.31\n",
      "23:07:46 --- Epoch: 13\tTrain loss: 0.0527\tValid loss: 0.1392\tTrain accuracy: 99.10\tValid accuracy: 96.28\n",
      "23:08:03 --- Epoch: 14\tTrain loss: 0.0423\tValid loss: 0.1096\tTrain accuracy: 99.31\tValid accuracy: 97.26\n",
      "23:08:19 --- Epoch: 15\tTrain loss: 0.0205\tValid loss: 0.1220\tTrain accuracy: 99.13\tValid accuracy: 97.18\n",
      "23:08:35 --- Epoch: 16\tTrain loss: 0.0206\tValid loss: 0.1100\tTrain accuracy: 99.32\tValid accuracy: 97.24\n",
      "23:08:51 --- Epoch: 17\tTrain loss: 0.0215\tValid loss: 0.0726\tTrain accuracy: 99.79\tValid accuracy: 98.31\n",
      "23:09:08 --- Epoch: 18\tTrain loss: 0.0282\tValid loss: 0.1617\tTrain accuracy: 98.74\tValid accuracy: 96.25\n",
      "23:09:24 --- Epoch: 19\tTrain loss: 0.0347\tValid loss: 0.0766\tTrain accuracy: 99.52\tValid accuracy: 98.12\n",
      "23:09:40 --- Epoch: 20\tTrain loss: 0.0205\tValid loss: 0.1226\tTrain accuracy: 99.14\tValid accuracy: 96.85\n",
      "23:09:56 --- Epoch: 21\tTrain loss: 0.0329\tValid loss: 0.0874\tTrain accuracy: 99.60\tValid accuracy: 97.97\n",
      "23:10:12 --- Epoch: 22\tTrain loss: 0.0131\tValid loss: 0.1111\tTrain accuracy: 99.32\tValid accuracy: 97.73\n",
      "23:10:29 --- Epoch: 23\tTrain loss: 0.0353\tValid loss: 0.0925\tTrain accuracy: 99.21\tValid accuracy: 97.94\n",
      "23:10:45 --- Epoch: 24\tTrain loss: 0.0276\tValid loss: 0.0655\tTrain accuracy: 99.75\tValid accuracy: 98.48\n",
      "23:11:01 --- Epoch: 25\tTrain loss: 0.0101\tValid loss: 0.0602\tTrain accuracy: 99.91\tValid accuracy: 98.69\n",
      "23:11:17 --- Epoch: 26\tTrain loss: 0.0187\tValid loss: 0.1013\tTrain accuracy: 99.29\tValid accuracy: 97.71\n",
      "23:11:33 --- Epoch: 27\tTrain loss: 0.0212\tValid loss: 0.0751\tTrain accuracy: 99.81\tValid accuracy: 98.33\n",
      "23:11:49 --- Epoch: 28\tTrain loss: 0.0094\tValid loss: 0.0545\tTrain accuracy: 99.89\tValid accuracy: 98.82\n",
      "23:12:06 --- Epoch: 29\tTrain loss: 0.0121\tValid loss: 0.0772\tTrain accuracy: 99.65\tValid accuracy: 98.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet50.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap our model in a PyTorchClassifier, which ART knows how to use\n",
    "classifier = PyTorchClassifier(\n",
    "    # model=WrappedModel(),\n",
    "    model=model,\n",
    "    clip_values=(0.0, 1.0),  # The adversarial sample tensor values will be within these values\n",
    "    loss=criterion,  # defined above\n",
    "    optimizer=optimizer,  # defined above\n",
    "    input_shape=(3, 32, 32),\n",
    "    nb_classes=43,\n",
    "    device_type=\"cpu\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gtsrb = ConcatDataset([base_dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1012 8 0\n"
     ]
    }
   ],
   "source": [
    "plot_output = []\n",
    "iterations = 10\n",
    "\n",
    "# For each number of iterations [1, 2, ..., 10], calculate the success rate/accuracy -> these are the X and Y coordinates of the graph\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "total_img = 0\n",
    "total_14 = 0\n",
    "for i in range(iterations):\n",
    "    # Define an attack that only runs until this max iteration\n",
    "    attack = BasicIterativeMethod(estimator=classifier, max_iter=i, batch_size=1, verbose = False)\n",
    "    success_rates = []\n",
    "    for j, (image, true_label) in enumerate(combined_gtsrb):\n",
    "        total_img += 1 \n",
    "        # image is an image, given as a tensor with shape [3, 32, 32]\n",
    "        # true_label is a simple int\n",
    "        # Add batch dimension\n",
    "        image = torch.unsqueeze(image, dim=0)  # shape == [1, 3, 32, 32]\n",
    "        # Omvormen naar numpy array\n",
    "        image_numpy = image.numpy()\n",
    "        true_label_numpy = np.array([true_label])\n",
    "        # Genereer adversarial sample\n",
    "        X_adv = attack.generate(image_numpy)  # shape == [1, 3, 32, 32]\n",
    "        # Model prediction op de gewone image. Deze kan ook fout zijn ten opzichte van het echte label!\n",
    "        normal_prediction = torch.argmax(model(image)).item()\n",
    "        # Prediction van de adversarial sample\n",
    "        adversarial_prediction = torch.argmax(model(torch.from_numpy(X_adv))).item()\n",
    "        # Is the adversarial attack successful or not?\n",
    "        # How do you define a successful attack?\n",
    "        # The definition below is just an example\n",
    "        if true_label == 14:\n",
    "                total_14 += 1\n",
    "        elif true_label == 14 and adversarial_prediction == 14:\n",
    "                tp += 1\n",
    "        elif true_label == 14 and adversarial_prediction != 14:\n",
    "                fn += 1\n",
    "        elif true_label != 14 and adversarial_prediction != 14:\n",
    "                tn += 1\n",
    "        elif true_label != 14 and adversarial_prediction == 14:\n",
    "                fp += 1\n",
    "\n",
    "        if j > 100: \n",
    "                break\n",
    "#     ASR = success_rates.count(True) / len(success_rates)\n",
    "#     accuracy_score = (1-ASR) \n",
    "#     plot_output.append((i, accuracy_score))\n",
    "# Plot output should contain our X, y coordinates. List[(x, y), (x, y), ...]\n",
    "print(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_14, total_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1012 8 0\n"
     ]
    }
   ],
   "source": [
    "plot_output = []\n",
    "iterations = 10\n",
    "\n",
    "# For each number of iterations [1, 2, ..., 10], calculate the success rate/accuracy -> these are the X and Y coordinates of the graph\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0 \n",
    "fn = 0\n",
    "total_img = 0\n",
    "total_14 = 0\n",
    "for i in range(iterations):\n",
    "    # Define an attack that only runs until this max iteration\n",
    "    attack = BasicIterativeMethod(estimator=classifier, max_iter=i, batch_size=1, verbose = False)\n",
    "    success_rates = []\n",
    "    for j, (image, true_label) in enumerate(combined_gtsrb):\n",
    "        total_img += 1 \n",
    "        # image is an image, given as a tensor with shape [3, 32, 32]\n",
    "        # true_label is a simple int\n",
    "        # Add batch dimension\n",
    "        image = torch.unsqueeze(image, dim=0)  # shape == [1, 3, 32, 32]\n",
    "        # Omvormen naar numpy array\n",
    "        image_numpy = image.numpy()\n",
    "        true_label_numpy = np.array([true_label])\n",
    "        # Genereer adversarial sample\n",
    "        X_adv = attack.generate(image_numpy)  # shape == [1, 3, 32, 32]\n",
    "        # Model prediction op de gewone image. Deze kan ook fout zijn ten opzichte van het echte label!\n",
    "        normal_prediction = torch.argmax(model(image)).item()\n",
    "        # Prediction van de adversarial sample\n",
    "        adversarial_prediction = torch.argmax(model(torch.from_numpy(X_adv))).item()\n",
    "        # Is the adversarial attack successful or not?\n",
    "        # How do you define a successful attack?\n",
    "        # The definition below is just an example\n",
    "        if normal_prediction == 14:\n",
    "                total_14 += 1\n",
    "        elif normal_prediction == 14 and adversarial_prediction == 14:\n",
    "                tp += 1\n",
    "        elif normal_prediction == 14 and adversarial_prediction != 14:\n",
    "                fn += 1\n",
    "        elif normal_prediction != 14 and adversarial_prediction != 14:\n",
    "                tn += 1\n",
    "        elif normal_prediction != 14 and adversarial_prediction == 14:\n",
    "                fp += 1\n",
    "\n",
    "        if j > 100: \n",
    "                break\n",
    "#     ASR = success_rates.count(True) / len(success_rates)\n",
    "#     accuracy_score = (1-ASR) \n",
    "#     plot_output.append((i, accuracy_score))\n",
    "# Plot output should contain our X, y coordinates. List[(x, y), (x, y), ...]\n",
    "print(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "classes = ['Stop-sign', 'Adversarial ']\n",
    "\n",
    "figure, ax = plot_confusion_matrix(conf_mat = confusion_values,\n",
    "                                   class_names = classes,\n",
    "                                   show_absolute = False,\n",
    "                                   show_normed = True,\n",
    "                                   colorbar = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix_resnet50 = confusion_matrix(adversarial_prediction, normal_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_img, total_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [p[0] for p in plot_output]\n",
    "y = [p[1] for p in plot_output]\n",
    "# Plot the success rate over\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(' IFGSM Attack Success Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.defences.trainer import AdversarialTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = BasicIterativeMethod(estimator=classifier, max_iter=10, batch_size=1)\n",
    "adv_trainer = AdversarialTrainer(classifier= classifier, attacks = attack, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = BasicIterativeMethod(estimator=classifier, max_iter=10, batch_size=1)\n",
    "adv_trainer = AdversarialTrainer(classifier= classifier, attacks = attack, ratio=0.5)\n",
    "\n",
    "for j, (image, true_label) in enumerate(train_dataset):\n",
    "    # image = torch.unsqueeze(image, dim=0) \n",
    "    # shape == [1, 3, 32, 32]\n",
    "    image_numpy = image.numpy()\n",
    "    true_label_numpy = np.array([true_label])\n",
    "    # Generate adversarial sample\n",
    "    adv_trainer_fit = adv_trainer.fit(image_numpy, true_label_numpy, batch = 64, nb_epochs = 30) # shape == [3, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (image, true_label) in enumerate(train_dataset):\n",
    "    image = image.to('cpu')\n",
    "    # image is an image,\n",
    "    # true_label is a simple int\n",
    "    # Add batch dimension\n",
    "    image = torch.unsqueeze(image, dim=0) # shape == [1, 3, 32, 32]\n",
    "    image_numpy = image.numpy()\n",
    "    true_label = torch.tensor(true_label)\n",
    "    true_label = true_label.to('cpu')\n",
    "    true_label_numpy = np.array([true_label])\n",
    "    \n",
    "    # Generate adversarial sample\n",
    "    adv_trainer_fit = adv_trainer.fit(image_numpy, true_label_numpy, batch = 64, nb_epochs = 30) # shape == [1, 3, 32, 32]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFool attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFool adversarial training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFGSM attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFGSM adversarial training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = (sum(p.numel() for p in model.parameters()))\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (3, 32, 32))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (3, 32, 32))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "# constant for classes\n",
    "classes = ( '0:Speed limit (20km/h)',\n",
    "            '1:Speed limit (30km/h)', \n",
    "            '2:Speed limit (50km/h)', \n",
    "            '3:Speed limit (60km/h)', \n",
    "            '4:Speed limit (70km/h)', \n",
    "            '5:Speed limit (80km/h)', \n",
    "            '6:End of speed limit (80km/h)', \n",
    "            '7:Speed limit (100km/h)', \n",
    "            '8:Speed limit (120km/h)', \n",
    "            '9:No passing', \n",
    "            '10:No passing veh over 3.5 tons', \n",
    "            '11:Right-of-way at intersection', \n",
    "            '12:Priority road', \n",
    "            '13:Yield', \n",
    "            '14:Stop', \n",
    "            '15:No vehicles', \n",
    "            '16:Veh > 3.5 tons prohibited', \n",
    "            '17:No entry', \n",
    "            '18:General caution', \n",
    "            '19:Dangerous curve left', \n",
    "            '20:Dangerous curve right', \n",
    "            '21:Double curve', \n",
    "            '22:Bumpy road', \n",
    "            '23:Slippery road', \n",
    "            '24:Road narrows on the right', \n",
    "            '25:Road work', \n",
    "            '26:Traffic signals', \n",
    "            '27:Pedestrians', \n",
    "            '28:Children crossing', \n",
    "            '29:Bicycles crossing', \n",
    "            '30:Beware of ice/snow',\n",
    "            '31:Wild animals crossing', \n",
    "            '32:End speed + passing limits', \n",
    "            '33:Turn right ahead', \n",
    "            '34:Turn left ahead', \n",
    "            '35:Ahead only', \n",
    "            '36:Go straight or right', \n",
    "            '37:Go straight or left', \n",
    "            '38:Keep right', \n",
    "            '39:Keep left', \n",
    "            '40:Roundabout mandatory', \n",
    "            '41:End of no passing', \n",
    "            '42:End no passing veh > 3.5 tons')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "#                      columns = [i for i in classes])\n",
    "# plt.figure(figsize = (40,15))\n",
    "# sn.heatmap(df_cm, annot=True)\n",
    "# plt.savefig('output.png')\n",
    "\n",
    "\n",
    "# print(cf_matrix)\n",
    "# cf_report = classification_report(y_true, y_pred)\n",
    "# print(cf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    from sklearn import metrics\n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report\n",
    "\n",
    "\n",
    "get_classification_report(y_test = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, recall_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sn \n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (40,15))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('Resnet50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "\n",
    "    if with_avg_total:\n",
    "        aveTotal = lines[len(lines) - 1].split()\n",
    "        classes.append('avg/total')\n",
    "        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
    "        plotMat.append(vAveTotal)\n",
    "\n",
    "\n",
    "    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true, y_pred) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
