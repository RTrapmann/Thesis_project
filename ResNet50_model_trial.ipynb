{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet50\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters  \n",
    "epochs = 3   #the nn will train 29 times \n",
    "learning_rate = 0.0001 #how much the weight will be updated each time \n",
    "batch_size = 64 \n",
    "classes = 43 \n",
    "img_size = 32\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3403, 0.3121, 0.3214),\n",
    "                        (0.2724, 0.2608, 0.2669))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.GTSRB(\n",
    "    root='./data', split = 'test', transform=transforms, download=True)\n",
    "\n",
    "# train loader \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size\n",
    ", shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<torch.utils.data.dataloader.DataLoader object at 0x7fd58c1ece80>, <torch.utils.data.dataloader.DataLoader object at 0x7fd5b33d7640>)\n"
     ]
    }
   ],
   "source": [
    "def get_train_valid_loader(\n",
    "                           batch_size,\n",
    "                           augment,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           num_workers=2):\n",
    "\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "\n",
    "    # load the dataset\n",
    "\n",
    "    base_dataset = datasets.ImageFolder(\n",
    "        root='/volumes1/thesis/notebooks/data/gtsrb/GTSRB/Training', transform=transforms,\n",
    "    )\n",
    "\n",
    "    # TODO\n",
    "    split_datasets = torch.utils.data.random_split(base_dataset, [0.20,0.8])\n",
    "    global val_dataset \n",
    "    val_dataset = split_datasets[0]\n",
    "    train_dataset = split_datasets[1]\n",
    "    \n",
    "\n",
    "    global num_train \n",
    "    num_train= len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    global split \n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "    #train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    #train_sampler = SubsetRandomSampler(train_idx)\n",
    "    #valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "    global train_loader \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = train_sampler\n",
    "    )\n",
    "    global valid_loader \n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, \n",
    "        #sampler = valid_sampler\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "print(get_train_valid_loader(batch_size = 64, augment = True, random_seed = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader, device):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            y_prob = model(X)\n",
    "            _, predicted_labels = torch.max(y_prob, 1)\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, valid_losses):\n",
    "    '''\n",
    "    Function for plotting training and validation losses\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    #plt.style.use('seaborn')\n",
    "\n",
    "    train_losses = np.array(train_losses) \n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
    "\n",
    "    ax.plot(train_losses, color='blue', label='Training loss') \n",
    "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
    "    ax.set(title=\"Loss over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss') \n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    '''\n",
    "    Function for the training step of the training loop\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        y_hat= model(X) \n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function, without a learning step (backward pass)\n",
    "\n",
    "def validate(valid_loader, model, criterion, device):\n",
    "    '''\n",
    "    Function for the validation step of the training loop\n",
    "    '''\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "    \n",
    "        X = X.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # Forward pass and record loss\n",
    "        y_hat= model(X)    # predicted\n",
    "        loss = criterion(y_hat, y_true) \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    \n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader, device=device)\n",
    "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "\n",
    "    plot_losses(train_losses, valid_losses)\n",
    "    \n",
    "    return model, optimizer, (train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "model.fc = torch.nn.Linear(2048,43)\n",
    "model.conv1 = torch.nn.Conv2d(3,64,kernel_size=5,stride=1)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(random_seed)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:32:31 --- Epoch: 0\tTrain loss: 2.5560\tValid loss: 1.5238\tTrain accuracy: 57.35\tValid accuracy: 53.55\n",
      "21:32:47 --- Epoch: 1\tTrain loss: 0.9968\tValid loss: 0.6054\tTrain accuracy: 87.72\tValid accuracy: 82.09\n",
      "21:33:03 --- Epoch: 2\tTrain loss: 0.3226\tValid loss: 0.3136\tTrain accuracy: 96.10\tValid accuracy: 90.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet50.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFGSM\n",
    "\n",
    "def ifgsm(model, x, y, device, epsilon=0.01, alpha=0.01, num_iter=10):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using the IFGSM attack.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A PyTorch model.\n",
    "    - x: Input data, a tensor of shape (batch_size, input_dim).\n",
    "    - y: Target labels, a tensor of shape (batch_size).\n",
    "    - device: The device to use (either 'cpu' or 'cuda').\n",
    "    - epsilon: The maximum perturbation.\n",
    "    - alpha: The step size for the attack.\n",
    "    - num_iter: The number of iterations for the attack.\n",
    "\n",
    "    Returns:\n",
    "    - A tensor of shape (batch_size, input_dim) containing the adversarial examples.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move the data and labels to the device\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Set the minimum and maximum values for the input data\n",
    "    min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    # Set the perturbation to zero\n",
    "    perturbation = torch.zeros_like(x, requires_grad=True)\n",
    "\n",
    "    # Set the flag to False\n",
    "    fooling = False\n",
    "\n",
    "    # Loop over the number of iterations\n",
    "    for _ in range(num_iter):\n",
    "        # Forward pass\n",
    "        logits = model(x + perturbation)\n",
    "\n",
    "        # Get the prediction\n",
    "        _, pred = logits.max(1)\n",
    "\n",
    "        # Check if the prediction is different from the target label\n",
    "        if not torch.eq(pred, y).all():\n",
    "            fooling = True\n",
    "            break\n",
    "\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Get the gradient of the perturbation\n",
    "        grad = perturbation.grad.data\n",
    "\n",
    "        # Calculate the sign of the gradient\n",
    "        sign_grad = grad.sign()\n",
    "\n",
    "        # Calculate the value to add to the perturbation\n",
    "        with torch.no_grad():\n",
    "            perturbation += alpha * sign_grad\n",
    "\n",
    "        # Clamp the perturbation between the minimum and maximum values\n",
    "        perturbation = torch.clamp(perturbation, min_val - x, max_val - x)\n",
    "\n",
    "        # Zero the gradients\n",
    "        model.zero_grad()\n",
    "        # perturbation.grad.zero_()\n",
    "        perturbation = torch.zeros_like(x, requires_grad=True)\n",
    "\n",
    "\n",
    "    # Project the perturbation onto the l_infinity ball\n",
    "    perturbation = epsilon * perturbation.sign()\n",
    "\n",
    "    # Clamp the perturbation between the minimum and maximum values\n",
    "    perturbation = torch.clamp(perturbation, min_val - x, max_val - x)\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Return the adversarial examples\n",
    "    return x + perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \n",
    "\n",
    "# Set the number of epochs for adversarial training\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over the training data\n",
    "    for x, y in train_loader:\n",
    "        # Move the data to the device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Create adversarial examples using IFGSM\n",
    "        x_adv = ifgsm(model, x, y, device)\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(model(x_adv), y)\n",
    "        # Backpropagate the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# Set the model back to training mode\n",
    "fgsm_model = model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgsm_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "        output = fgsm_model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "# constant for classes\n",
    "classes = ( '0:Speed limit (20km/h)',\n",
    "            '1:Speed limit (30km/h)', \n",
    "            '2:Speed limit (50km/h)', \n",
    "            '3:Speed limit (60km/h)', \n",
    "            '4:Speed limit (70km/h)', \n",
    "            '5:Speed limit (80km/h)', \n",
    "            '6:End of speed limit (80km/h)', \n",
    "            '7:Speed limit (100km/h)', \n",
    "            '8:Speed limit (120km/h)', \n",
    "            '9:No passing', \n",
    "            '10:No passing veh over 3.5 tons', \n",
    "            '11:Right-of-way at intersection', \n",
    "            '12:Priority road', \n",
    "            '13:Yield', \n",
    "            '14:Stop', \n",
    "            '15:No vehicles', \n",
    "            '16:Veh > 3.5 tons prohibited', \n",
    "            '17:No entry', \n",
    "            '18:General caution', \n",
    "            '19:Dangerous curve left', \n",
    "            '20:Dangerous curve right', \n",
    "            '21:Double curve', \n",
    "            '22:Bumpy road', \n",
    "            '23:Slippery road', \n",
    "            '24:Road narrows on the right', \n",
    "            '25:Road work', \n",
    "            '26:Traffic signals', \n",
    "            '27:Pedestrians', \n",
    "            '28:Children crossing', \n",
    "            '29:Bicycles crossing', \n",
    "            '30:Beware of ice/snow',\n",
    "            '31:Wild animals crossing', \n",
    "            '32:End speed + passing limits', \n",
    "            '33:Turn right ahead', \n",
    "            '34:Turn left ahead', \n",
    "            '35:Ahead only', \n",
    "            '36:Go straight or right', \n",
    "            '37:Go straight or left', \n",
    "            '38:Keep right', \n",
    "            '39:Keep left', \n",
    "            '40:Roundabout mandatory', \n",
    "            '41:End of no passing', \n",
    "            '42:End no passing veh > 3.5 tons')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "#                      columns = [i for i in classes])\n",
    "# plt.figure(figsize = (40,15))\n",
    "# sn.heatmap(df_cm, annot=True)\n",
    "# plt.savefig('output.png')\n",
    "\n",
    "\n",
    "# print(cf_matrix)\n",
    "# cf_report = classification_report(y_true, y_pred)\n",
    "# print(cf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Micro Precision: 0.94\n",
      "Micro Recall: 0.94\n",
      "Micro F1-score: 0.94\n",
      "\n",
      "Micro Sensitivity: 0.94\n",
      "\n",
      "Macro Precision: 0.91\n",
      "Macro Recall: 0.90\n",
      "Macro F1-score: 0.90\n",
      "\n",
      "Macro Sensitivity: 0.90\n",
      "\n",
      "Weighted Precision: 0.94\n",
      "Weighted Recall: 0.94\n",
      "Weighted F1-score: 0.94\n",
      "Weighted Sensitivity: 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, recall_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifgsm_accuracy = ifgsm(fgsm_model, x, y, device, epsilon=0.01, alpha=0.01, num_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CW\n",
    "\n",
    "def carlini_wagner(model, x, y, device, c=1, kappa=0, lr=0.01, num_iter=100):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using the Carlini-Wagner attack.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A PyTorch model.\n",
    "    - x: Input data, a tensor of shape (batch_size, input_dim).\n",
    "    - y: Target labels, a tensor of shape (batch_size).\n",
    "    - device: The device to use (either 'cpu' or 'cuda').\n",
    "    - c: The constant to use in the attack.\n",
    "    - kappa: The confidence level to use in the attack.\n",
    "    - lr: The learning rate for the attack.\n",
    "    - num_iter: The number of iterations for the attack.\n",
    "\n",
    "    Returns:\n",
    "    - A tensor of shape (batch_size, input_dim) containing the adversarial examples.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move the data and labels to the device\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Set the minimum and maximum values for the input data\n",
    "    min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    # Set the perturbation to zero\n",
    "    perturbation = torch.zeros_like(x, requires_grad=True)\n",
    "\n",
    "    # Set the loss function\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Set the optimizer\n",
    "    optimizer = optim.Adam([perturbation], lr=lr)\n",
    "\n",
    "    # Set the confidence to be the maximum value of the logits\n",
    "    confidence = torch.max(model(x)).detach() * kappa\n",
    "\n",
    "    # Loop over the number of iterations\n",
    "    for _ in range(num_iter):\n",
    "        # Forward pass\n",
    "        logits = model(x + perturbation)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = (loss_fn(logits, y.clone()) - confidence).clamp(min=0)\n",
    "\n",
    "        # Backpropagate the gradients\n",
    "        loss.sum().backward(retain_graph=True)\n",
    "\n",
    "        # Update the perturbation\n",
    "        optimizer.step()\n",
    "\n",
    "        # Project the perturbation onto the l_infinity ball\n",
    "        perturbation.data.renorm_(2, 0, c)\n",
    "\n",
    "        # Clamp the perturbation between the minimum and maximum values\n",
    "        perturbation = torch.clamp(perturbation, min_val - x, max_val - x)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Return the adversarial examples\n",
    "    return x + perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepfool \n",
    "def deepfool(model, x, y, device):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples using the DeepFool attack.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A PyTorch model.\n",
    "    - x: Input data, a tensor of shape (batch_size, input_dim).\n",
    "    - y: Target labels, a tensor of shape (batch_size).\n",
    "    - device: The device to use (either 'cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - A tensor of shape (batch_size, input_dim) containing the adversarial examples.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move the data and labels to the device\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # Set the minimum and maximum values for the input data\n",
    "    min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    # Set the perturbation to zero\n",
    "    perturbation = torch.zeros_like(x, requires_grad=True)\n",
    "\n",
    "    # Set the flag to False\n",
    "    fooling = False\n",
    "\n",
    "    # Set the maximum number of iterations\n",
    "    max_iter = 100\n",
    "\n",
    "    # Set the overshoot to 0.02\n",
    "    overshoot = 0.02\n",
    "\n",
    "    # Set the iteration to 0\n",
    "    itr = 0\n",
    "\n",
    "    # Set the loss function\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    while not fooling:\n",
    "        # Increment the iteration counter\n",
    "        itr += 1\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(x + perturbation)\n",
    "\n",
    "        # Get the prediction\n",
    "        _, pred = logits.max(1)\n",
    "\n",
    "        # Check if the prediction is different from the target label\n",
    "        if not torch.eq(pred, y).all():\n",
    "            fooling = True\n",
    "            break\n",
    "\n",
    "\n",
    "        if itr >= max_iter:\n",
    "            break\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(logits, y)\n",
    "        \n",
    "        # Backpropagate the gradients\n",
    "        loss.sum().backward()\n",
    "\n",
    "        # Get the gradient of the perturbation\n",
    "        grad = perturbation.grad.data\n",
    "\n",
    "        # Calculate the sign of the gradient\n",
    "        sign_grad = grad.sign()\n",
    "        # sign_grad = sign_grad.view(-1, dim)\n",
    "\n",
    "        # Calculate the norm of the gradient\n",
    "        grad_norm = grad.view(grad.shape[0], -1).norm(dim=1)\n",
    "        # perturbation += overshoot * sign_grad / grad_norm(-1,1)\n",
    "\n",
    "        # Calculate the value to add to the perturbation\n",
    "        with torch.no_grad():\n",
    "            perturbation += overshoot * sign_grad / grad_norm.view(-1, 1)\n",
    "\n",
    "        # Clamp the perturbation between the minimum and maximum values\n",
    "        perturbation = torch.clamp(perturbation, min_val - x, max_val - x)\n",
    "\n",
    "        # Zero the gradients\n",
    "        model.zero_grad()\n",
    "        perturbation.grad.zero_()\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Return the adversarial examples\n",
    "    return x + perturbation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = (sum(p.numel() for p in model.parameters()))\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 45.90\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (3, 32, 32))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "# constant for classes\n",
    "classes = ( '0:Speed limit (20km/h)',\n",
    "            '1:Speed limit (30km/h)', \n",
    "            '2:Speed limit (50km/h)', \n",
    "            '3:Speed limit (60km/h)', \n",
    "            '4:Speed limit (70km/h)', \n",
    "            '5:Speed limit (80km/h)', \n",
    "            '6:End of speed limit (80km/h)', \n",
    "            '7:Speed limit (100km/h)', \n",
    "            '8:Speed limit (120km/h)', \n",
    "            '9:No passing', \n",
    "            '10:No passing veh over 3.5 tons', \n",
    "            '11:Right-of-way at intersection', \n",
    "            '12:Priority road', \n",
    "            '13:Yield', \n",
    "            '14:Stop', \n",
    "            '15:No vehicles', \n",
    "            '16:Veh > 3.5 tons prohibited', \n",
    "            '17:No entry', \n",
    "            '18:General caution', \n",
    "            '19:Dangerous curve left', \n",
    "            '20:Dangerous curve right', \n",
    "            '21:Double curve', \n",
    "            '22:Bumpy road', \n",
    "            '23:Slippery road', \n",
    "            '24:Road narrows on the right', \n",
    "            '25:Road work', \n",
    "            '26:Traffic signals', \n",
    "            '27:Pedestrians', \n",
    "            '28:Children crossing', \n",
    "            '29:Bicycles crossing', \n",
    "            '30:Beware of ice/snow',\n",
    "            '31:Wild animals crossing', \n",
    "            '32:End speed + passing limits', \n",
    "            '33:Turn right ahead', \n",
    "            '34:Turn left ahead', \n",
    "            '35:Ahead only', \n",
    "            '36:Go straight or right', \n",
    "            '37:Go straight or left', \n",
    "            '38:Keep right', \n",
    "            '39:Keep left', \n",
    "            '40:Roundabout mandatory', \n",
    "            '41:End of no passing', \n",
    "            '42:End no passing veh > 3.5 tons')\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "#                      columns = [i for i in classes])\n",
    "# plt.figure(figsize = (40,15))\n",
    "# sn.heatmap(df_cm, annot=True)\n",
    "# plt.savefig('output.png')\n",
    "\n",
    "\n",
    "# print(cf_matrix)\n",
    "# cf_report = classification_report(y_true, y_pred)\n",
    "# print(cf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.973865</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.978576</td>\n",
       "      <td>720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.976155</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.962528</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.935578</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.951601</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.964384</td>\n",
       "      <td>0.902564</td>\n",
       "      <td>0.932450</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.937768</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.923890</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.907834</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.922717</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.938416</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.912981</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.903915</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.947644</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.902743</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.900585</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.918841</td>\n",
       "      <td>0.899929</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.891266</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.865455</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.851765</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>0.856805</td>\n",
       "      <td>420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.822249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863333</td>\n",
       "      <td>0.784848</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.697674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.827482</td>\n",
       "      <td>0.822249</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>12630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.819407</td>\n",
       "      <td>720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.744584</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>0.802704</td>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.857513</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>0.791866</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.731397</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.781765</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.780780</td>\n",
       "      <td>0.753367</td>\n",
       "      <td>0.759493</td>\n",
       "      <td>12630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741525</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.759219</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.843450</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706693</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.749478</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.539394</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.633968</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>0.659558</td>\n",
       "      <td>630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.553633</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.484472</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.411215</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.325991</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "13             0.973865  0.983333  0.978576    720.000000\n",
       "12             0.976155  0.949275  0.962528    690.000000\n",
       "10             0.935578  0.968182  0.951601    660.000000\n",
       "35             0.964384  0.902564  0.932450    390.000000\n",
       "37             0.918033  0.933333  0.925620     60.000000\n",
       "9              0.937768  0.910417  0.923890    480.000000\n",
       "33             0.907834  0.938095  0.922717    210.000000\n",
       "17             0.938416  0.888889  0.912981    360.000000\n",
       "16             0.969466  0.846667  0.903915    150.000000\n",
       "15             0.947644  0.861905  0.902743    210.000000\n",
       "14             0.950617  0.855556  0.900585    270.000000\n",
       "38             0.881780  0.918841  0.899929    690.000000\n",
       "31             0.859107  0.925926  0.891266    270.000000\n",
       "6              0.952000  0.793333  0.865455    150.000000\n",
       "11             0.851765  0.861905  0.856805    420.000000\n",
       "22             0.830645  0.858333  0.844262    120.000000\n",
       "34             0.920792  0.775000  0.841629    120.000000\n",
       "accuracy       0.822249  0.822249  0.822249      0.822249\n",
       "4              0.863333  0.784848  0.822222    660.000000\n",
       "32             0.697674  1.000000  0.821918     60.000000\n",
       "weighted avg   0.827482  0.822249  0.821211  12630.000000\n",
       "1              0.795812  0.844444  0.819407    720.000000\n",
       "2              0.744584  0.870667  0.802704    750.000000\n",
       "40             0.841463  0.766667  0.802326     90.000000\n",
       "7              0.857513  0.735556  0.791866    450.000000\n",
       "36             0.931034  0.675000  0.782609    120.000000\n",
       "25             0.731397  0.839583  0.781765    480.000000\n",
       "macro avg      0.780780  0.753367  0.759493  12630.000000\n",
       "8              0.741525  0.777778  0.759219    450.000000\n",
       "18             0.843450  0.676923  0.751067    390.000000\n",
       "3              0.706693  0.797778  0.749478    450.000000\n",
       "21             0.901639  0.611111  0.728477     90.000000\n",
       "39             0.712766  0.744444  0.728261     90.000000\n",
       "42             0.885246  0.600000  0.715232     90.000000\n",
       "26             0.660377  0.777778  0.714286    180.000000\n",
       "20             0.539394  0.988889  0.698039     90.000000\n",
       "5              0.633968  0.687302  0.659558    630.000000\n",
       "23             0.575540  0.533333  0.553633    150.000000\n",
       "0              0.710526  0.450000  0.551020     60.000000\n",
       "29             0.608696  0.466667  0.528302     90.000000\n",
       "24             0.555556  0.444444  0.493827     90.000000\n",
       "28             0.453488  0.520000  0.484472    150.000000\n",
       "41             0.455882  0.516667  0.484375     60.000000\n",
       "19             0.461538  0.500000  0.480000     60.000000\n",
       "27             0.468085  0.366667  0.411215     60.000000\n",
       "30             0.480519  0.246667  0.325991    150.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    from sklearn import metrics\n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report\n",
    "\n",
    "\n",
    "get_classification_report(y_test = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.82\n",
      "\n",
      "Micro Precision: 0.82\n",
      "Micro Recall: 0.82\n",
      "Micro F1-score: 0.82\n",
      "\n",
      "Micro Sensitivity: 0.82\n",
      "\n",
      "Macro Precision: 0.78\n",
      "Macro Recall: 0.75\n",
      "Macro F1-score: 0.76\n",
      "\n",
      "Macro Sensitivity: 0.75\n",
      "\n",
      "Weighted Precision: 0.83\n",
      "Weighted Recall: 0.82\n",
      "Weighted F1-score: 0.82\n",
      "Weighted Sensitivity: 0.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, recall_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='micro')))\n",
    "print('Micro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='macro')))\n",
    "print('Macro Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_true, y_pred, average='weighted')))\n",
    "print('Weighted Sensitivity: {:.2f}\\n'.format(recall_score(y_true, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cf_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cf_report(y_true, y_pred, zero_division \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, target_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m0:Speed limit (20km/h)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m1:Speed limit (30km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m2:Speed limit (50km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m3:Speed limit (60km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m4:Speed limit (70km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m5:Speed limit (80km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m6:End of speed limit (80km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m7:Speed limit (100km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m8:Speed limit (120km/h)\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m9:No passing\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m10:No passing veh over 3.5 tons\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m11:Right-of-way at intersection\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m12:Priority road\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m13:Yield\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     15\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m14:Stop\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m15:No vehicles\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     17\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m16:Veh > 3.5 tons prohibited\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     18\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m17:No entry\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     19\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m18:General caution\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     20\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m19:Dangerous curve left\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m20:Dangerous curve right\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     22\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m21:Double curve\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     23\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m22:Bumpy road\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     24\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m23:Slippery road\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     25\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m24:Road narrows on the right\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     26\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m25:Road work\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     27\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m26:Traffic signals\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     28\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m27:Pedestrians\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     29\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m28:Children crossing\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     30\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m29:Bicycles crossing\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     31\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m30:Beware of ice/snow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m31:Wild animals crossing\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     33\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m32:End speed + passing limits\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     34\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m33:Turn right ahead\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     35\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m34:Turn left ahead\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     36\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m35:Ahead only\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     37\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m36:Go straight or right\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     38\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m37:Go straight or left\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     39\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m38:Keep right\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     40\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m39:Keep left\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     41\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m40:Roundabout mandatory\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     42\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m41:End of no passing\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     43\u001b[0m             \u001b[39m'\u001b[39m\u001b[39m42:End no passing veh > 3.5 tons\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(cf_report)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cf_report' is not defined"
     ]
    }
   ],
   "source": [
    "cf_report(y_true, y_pred, zero_division = 0, target_names=['0:Speed limit (20km/h)',\n",
    "            '1:Speed limit (30km/h)', \n",
    "            '2:Speed limit (50km/h)', \n",
    "            '3:Speed limit (60km/h)', \n",
    "            '4:Speed limit (70km/h)', \n",
    "            '5:Speed limit (80km/h)', \n",
    "            '6:End of speed limit (80km/h)', \n",
    "            '7:Speed limit (100km/h)', \n",
    "            '8:Speed limit (120km/h)', \n",
    "            '9:No passing', \n",
    "            '10:No passing veh over 3.5 tons', \n",
    "            '11:Right-of-way at intersection', \n",
    "            '12:Priority road', \n",
    "            '13:Yield', \n",
    "            '14:Stop', \n",
    "            '15:No vehicles', \n",
    "            '16:Veh > 3.5 tons prohibited', \n",
    "            '17:No entry', \n",
    "            '18:General caution', \n",
    "            '19:Dangerous curve left', \n",
    "            '20:Dangerous curve right', \n",
    "            '21:Double curve', \n",
    "            '22:Bumpy road', \n",
    "            '23:Slippery road', \n",
    "            '24:Road narrows on the right', \n",
    "            '25:Road work', \n",
    "            '26:Traffic signals', \n",
    "            '27:Pedestrians', \n",
    "            '28:Children crossing', \n",
    "            '29:Bicycles crossing', \n",
    "            '30:Beware of ice/snow',\n",
    "            '31:Wild animals crossing', \n",
    "            '32:End speed + passing limits', \n",
    "            '33:Turn right ahead', \n",
    "            '34:Turn left ahead', \n",
    "            '35:Ahead only', \n",
    "            '36:Go straight or right', \n",
    "            '37:Go straight or left', \n",
    "            '38:Keep right', \n",
    "            '39:Keep left', \n",
    "            '40:Roundabout mandatory', \n",
    "            '41:End of no passing', \n",
    "            '42:End no passing veh > 3.5 tons'])\n",
    "print(cf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sn \n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27  26   0 ...   0   0   0]\n",
      " [  8 608  74 ...   0   0   0]\n",
      " [  2  22 653 ...   0   0   2]\n",
      " ...\n",
      " [  0   0   0 ...  69   0   0]\n",
      " [  0   0   0 ...   0  31   4]\n",
      " [  0   0   0 ...   0  33  54]]\n"
     ]
    }
   ],
   "source": [
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (40,15))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('Resnet50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "\n",
    "    if with_avg_total:\n",
    "        aveTotal = lines[len(lines) - 1].split()\n",
    "        classes.append('avg/total')\n",
    "        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
    "        plotMat.append(vAveTotal)\n",
    "\n",
    "\n",
    "    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    x_tick_marks = np.arange(3)\n",
    "    y_tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n",
    "    plt.yticks(y_tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classes')\n",
    "    plt.xlabel('Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true, y_pred) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e104bd40b3717451915a48eb0e1578acd631c83a179c8bd7a28647fdfca76f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
